version: 2.1

orbs:
  win: circleci/windows@2.2.0
  aws-s3: circleci/aws-s3@1.0.15
  aws-cli: circleci/aws-cli@1.0.0

commands:
  set_s3_pkg_urls:
    steps:
      - run:
          name: Set S3 URLs according to date and git hash
          environment:
            GIT_REVISION: << pipeline.git.revision >>
            PIPELINE_NUMBER: << pipeline.number >>
          command: |
            echo "export S3_PKG_BUCKET=salto-cli-releases" >> $BASH_ENV
            echo "export PKG_PREFIX=${GIT_REVISION:0:8}_${PIPELINE_NUMBER}" >> $BASH_ENV
            source $BASH_ENV
            echo "export S3_PKG_HASH_PREFIX=s3://${S3_PKG_BUCKET}/${CIRCLE_BRANCH}/${PKG_PREFIX}" >> $BASH_ENV
            source $BASH_ENV

  upload_pkg:
    parameters:
      workspace_dir:
        type: string

      out_filename:
        type: string

    steps:
      - set_s3_pkg_urls

      - store_artifacts:
          path: packages/<< parameters.workspace_dir >>/pkg
          destination: pkg/<< parameters.out_filename >>

      - aws-s3/sync:
          from: packages/<< parameters.workspace_dir >>/pkg
          to: ${S3_PKG_HASH_PREFIX}/<< parameters.out_filename >>

jobs:
  build:
    docker:
      - image: circleci/node:12.16

    resource_class: large

    steps:
      - restore_cache:
          keys:
            - v1-source-{{ .Branch }}
            - v1-source-master
            - v1-source-

      - checkout

      - save_cache:
          key: v1-source-{{ .Branch }}
          paths: .git

      # Download and cache dependencies
      - restore_cache:
          keys:
            - v2-yarn-deps-{{ arch }}-{{ checksum "yarn.lock" }}

      - run: yarn --frozen-lockfile

      - run:
          name: create packages_node_modules_cache.tar.gz
          command: tar cfz packages_node_modules_cache.tar.gz packages/*/node_modules

      - save_cache:
          paths:
            - ~/.cache/yarn
            - node_modules
            - packages_node_modules_cache.tar.gz

          key: v2-yarn-deps-{{ arch }}-{{ checksum "yarn.lock" }}

      - restore_cache:
          keys:
            - v3-build-{{ .Branch }}
            - v3-build-master
            - v3-build-

      - run:
          name: extract packages_node_modules_cache.tar.gz
          command: |
            if [ -f packages_node_modules_cache.tar.gz ]; then
              comm -12 <(
                ls packages | sort
              ) <(
                tar tf packages_node_modules_cache.tar.gz | sed -E "s/^packages\/([^/]+)\/.*/\1/" | sort | uniq
              ) |
                xargs -I{} tar xf packages_node_modules_cache.tar.gz --wildcards "packages/{}/**";
            fi

      - run:
          name: fix eslint cache
          command: yarn lerna exec ../../build_utils/fix_eslint_cache.sh

      - run:
          # eslint will verify that the license header exists on the linted source files, this step is
          # to verify that other non-linted files also contains the license header (and therefore this is
          # in the 'build' job)
          name: verify that the license header is prepend to the non eslint'd source files
          command: |
            # get the license header from the eslintrc configuration
            set -e
            if [ ! -f 'eslintrc.js' ]; then
              echo 'cannot find eslintrc.js file'
              exit 1
            fi
            license_header=$(node -e "var license_head = require('./eslintrc.js'); console.log(\`/*\${license_head.rules['header/header'][2].join('\n')}*/\`)")
            src_files_without_license_header=""
            for f in $(find . -type f -name '*.js' -not -path '*node_modules*' -not -path '*dist\/*' ); do
              if ! grep -qFx "$license_header" "$f"; then
                src_files_without_license_header+="$f\n"
              fi
            done

            if [ ! -z "$src_files_without_license_header" ]; then
              echo -e "the following source files do not contain license header:\n${src_files_without_license_header}"
              exit 1
            fi

      - run: yarn build

      - run:
          name: create packages_build_cache.tar.gz
          # Note: The build cache cannot include the dist directories -
          # they might contain old (e.g. renamed) files, which will leak into the current dist.
          # * The TypeScript compiler does not currently have an option to remove old files.
          # * Utilities such as ts-cleaner can break the build because they use heuristics and
          #   might wrongly remove needed build artifacts, e.g, generated code, wasm.
          command: tar cfz packages_build_cache.tar.gz packages/*/.eslintcache

      - save_cache:
          paths:
            - packages_build_cache.tar.gz
          key: v3-build-{{ .Branch }}

      - run:
          name: Remove unneeded files before saving workspace
          command: rm -f *.tar.gz

      - persist_to_workspace:
          root: .
          paths: '*'

      - run:
          name: Run unit tests
          command: yarn test --reporters=default --reporters=jest-junit
          environment:
            JEST_JUNIT_OUTPUT: "reports/unittests/test-results.xml"

      - store_test_results:
          path: reports

      - run:
          name: Upload coverage to codecov.io
          command: npx codecov -F unit_test -f coverage/*.json
          when: always

  publish_on_version_change:
    docker:
      - image: circleci/node:12.16

    steps:
      - attach_workspace:
          at: .

      - add_ssh_keys:
          fingerprints:
              - "49:dd:95:76:13:c0:cd:9d:75:48:b0:30:5c:3c:4c:17"

      - set_s3_pkg_urls

      - aws-cli/setup

      - run:
          name: Release version
          command: ./.circleci/scripts/release_version.sh << pipeline.git.base_revision >>

  e2e_test:
    docker:
      - image: circleci/node:12.16

    resource_class: large

    steps:
      - attach_workspace:
          at: .

      - run:
          name: Run E2E tests
          command: yarn test --reporters=default --reporters=jest-junit --coverage=false
          no_output_timeout: 20m
          environment:
            RUN_E2E_TESTS: '1'
            SALTO_LOG_LEVEL: 'warn'
            # enable telemetry for end2end so we can count more events
            # webpack configuration is irrelevant in this case and therefore
            # we explicitly configure it in here
            SALTO_TELEMETRY_DISABLE: '0'
            SALTO_TELEMETRY_URL: 'https://telemetry.salto.io'
            JEST_JUNIT_OUTPUT: 'reports/e2e/test-results.xml'

      - store_test_results:
          path: reports

  package_cli:
    docker:
      - image: circleci/node:12.16

    steps:
      - attach_workspace:
          at: .

      - run:
          name: Build native executables
          command: yarn workspace @salto-io/cli package

      - upload_pkg:
          workspace_dir: cli
          out_filename: cli

  test_cli_mac:
    macos:
      xcode: 11.3.0

    steps:
      - set_s3_pkg_urls

      - aws-s3/copy:
          from: ${S3_PKG_HASH_PREFIX}/cli/mac/salto
          to: .

      - run:
          command: chmod +x ./salto

      - run:
          name: run CLI --help
          command: ./salto --help

  test_cli_linux:
    docker:
      - image: circleci/node:12.16

    steps:
      - set_s3_pkg_urls

      - aws-s3/copy:
          from: ${S3_PKG_HASH_PREFIX}/cli/linux/salto
          to: .

      - run:
          command: chmod +x ./salto

      - run:
          name: run CLI --help
          command: ./salto --help

  test_cli_win:
    executor:
      name: win/default
      shell: bash.exe

    steps:
      - set_s3_pkg_urls

      - aws-s3/copy:
          from: ${S3_PKG_HASH_PREFIX}/cli/win/salto.exe
          to: .

      - run:
          name: run CLI --help
          command: ./salto.exe --help

  package_vscode_extension:
    docker:
      - image: circleci/node:12.16

    steps:
      - attach_workspace:
          at: .

      - run:
          name: Create a VSIX file
          command: yarn workspace salto-vscode package

      - upload_pkg:
          workspace_dir: vscode
          out_filename: vscode/salto.vsix

  sync_s3_pkg_latest:
    docker:
      - image: circleci/python

    steps:
      - set_s3_pkg_urls

      - aws-s3/sync:
          from: ${S3_PKG_HASH_PREFIX}/
          to: s3://${S3_PKG_BUCKET}/${CIRCLE_BRANCH}/latest/
          arguments: '--delete --acl public-read'

      - run:
          name: Create a marker file with the git hash
          command: touch ./PACKAGED_FROM.${PKG_PREFIX}

      - aws-s3/copy:
          from: ./PACKAGED_FROM.${PKG_PREFIX}
          to: s3://${S3_PKG_BUCKET}/${CIRCLE_BRANCH}/latest/
          arguments: '--acl public-read'

  build_and_upload_docs:
    docker:
      - image: circleci/node:12.16

    steps:
      - attach_workspace:
          at: .

      - aws-cli/setup

      - run:
          name: Build and upload docs
          command: cd docs && ./build.sh

workflows:
  version: 2

  commit:
    jobs:
      - build

      - e2e_test:
          requires:
            - build

      - test_cli_mac:
          requires:
            - package_cli

      - test_cli_linux:
          requires:
            - package_cli

      - test_cli_win:
          requires:
            - package_cli

      - package_cli:
          requires:
            - build
            # - e2e_test

      - package_vscode_extension:
          requires:
            - build
            # - e2e_test

      - sync_s3_pkg_latest:
          requires:
            - package_cli
            - package_vscode_extension

      - publish_on_version_change:
          filters:
            branches:
              only:
                - master
          requires:
            - build
            - e2e_test
      - build_and_upload_docs:
          name: build_and_upload_docs
          requires:
            - build
          filters:
            branches:
              only:
                - master
